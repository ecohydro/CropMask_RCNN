{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Project Prep for Aquaculture Mask R-CNN\n",
    "\n",
    "This notebook contains code related to processing and organizing Planet images (PlanetScope 3B Analytic SR products) and their associated object annotations for use by a Mask R-CNN model. \n",
    "\n",
    "The project data is organized within the `data` directory as follows:\n",
    "  + `aqua`: root directory for aquaculture data\n",
    "      + `planet`: full PlanetScope 3B Analytic SR scenes downloaded from Planet. \n",
    "      + `gridded_planet`: image chips (256x256) created from the raw PlanetScope scenes in `planet` and a JSON file with corresponding object annotations\n",
    "      + `train`: subset of image chips for use in model training\n",
    "          + `image`: raw GeoTiff image chip from `gridded_planet`\n",
    "          + `masks`: instance-specific GeoTiff masks for each object\n",
    "      + `test`: subset of image chips for use in model testing\n",
    "          + `image`: raw GeoTiff image chip from `gridded_planet`\n",
    "          + `masks`: instance-specific GeoTiff masks for each object\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "import math\n",
    "import random\n",
    "import rasterio # requires gdal to be installed from conda forge w/ \"conda install -c conda-forge gdal\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.io as skio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import skimage.draw\n",
    "from skimage import measure\n",
    "\n",
    "import aqua_preprocess as pp # preprocess script with directory variables\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Processing\n",
    "\n",
    "This project relies on Planet images that have been annotated with the locations of aquaculture farms for the training and testing of a Mask R-CNN model. These annotations have been generated in two ways:\n",
    "\n",
    "1. Fully annotated Planet scenes - annotations stored as binary bands of full Planet scenes stored in `planet` with filenames ending with `_labels.tif` \n",
    "\n",
    "2. JSON annotations - annotations created for previsouly created image chips (256x256 pixels) and recorded in `json` files stored within individual scene folders in `gridded_planet`\n",
    "\n",
    "For both annotation methods, image chips and object instance masks are created and stored in the `train`. Each image chip will be stored in its own directory that contains two subdirectories: `image_id/image` containing the raw GeoTiff image, and `image_id/masks` containing the image's object instance masks. \n",
    "\n",
    "At the time of model training, the `train` directory will then be sampled and a subset placed in `test`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Annotated Planet Scenes\n",
    "\n",
    "For each labeled Planet scene in `planet`, the following function will create a series of 256x256 image chips and instance masks and place them in the `train` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tclavelle/tana-crunch/CropMask_RCNN/data/aqua\n"
     ]
    }
   ],
   "source": [
    "# Check data directory\n",
    "print(pp.DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create image chips with masks of every GeoTiff file in a directory\n",
    "def prep_labeled_scenes(tiff_directory, prep_directory):\n",
    "    \n",
    "    # Get all GeoTiff filnames in specified directory\n",
    "    files = np.array(os.listdir(tiff_directory))\n",
    "    tiffs = pd.Series(files).str.contains('_labels.tif')\n",
    "    files = files[tiffs] \n",
    "    \n",
    "    # Loop over files\n",
    "    for filename in files:\n",
    "        \n",
    "        # Get image name to use for creating directory\n",
    "        image_name = filename.split(\"_\")[0:3]\n",
    "        image_name = \"%s_%s_%s\" % (image_name[0], image_name[1], image_name[2])\n",
    "        \n",
    "        # Image directory and subdirectories\n",
    "        image_dir = prep_directory + '/' + image_name + '/'        \n",
    "        \n",
    "        # Print filenames\n",
    "        print('filename: ' + filename + '\\n' + 'image name: ' + image_name)\n",
    "        \n",
    "        # Iterate over image blocks - which are 256x256 - and save new GeoTiffs\n",
    "        with rasterio.open(os.path.join(tiff_directory, filename)) as src:\n",
    "            \n",
    "            # Get block dimensions of src\n",
    "            for ji, window in src.block_windows(1):\n",
    "                \n",
    "                # read B,G,R,NIR band\n",
    "                r = src.read((1,2,3,4), window=window)\n",
    "                \n",
    "                # Skip image if missing data\n",
    "                if 0 in r:\n",
    "                    continue\n",
    "           \n",
    "                else:\n",
    "                    \n",
    "                    # Create chip id\n",
    "                    chip_name = image_name + '_' + str(ji[0]) + '_' + str(ji[1])                    \n",
    "                    \n",
    "                    # Create directory for image chip and subdirectories for image and labels\n",
    "                    chip_dir = prep_directory + '/' + chip_name + '/'                    \n",
    "                    img_dir = chip_dir + '/image/'\n",
    "                    mask_dir = chip_dir + '/class_masks/'\n",
    "                    \n",
    "                    # list of directories to map over\n",
    "                    dirs = [chip_dir, img_dir, mask_dir]\n",
    "                    \n",
    "                    # Make chip directory and subdirectories\n",
    "                    for d in dirs:\n",
    "                        pathlib.Path(d).mkdir(parents=True, exist_ok=True)\n",
    "                    \n",
    "                    # Open a new GeoTiff data file in which to save the image chip\n",
    "                    with rasterio.open((img_dir + chip_name + '.tif'), 'w', driver='GTiff',\n",
    "                               height=r.shape[1], width=r.shape[2], count=4,\n",
    "                               dtype=rasterio.uint16, crs=src.crs, \n",
    "                               transform=src.transform) as new_img:\n",
    "        \n",
    "                        # Write the rescaled image to the new GeoTiff\n",
    "                        new_img.write(r)\n",
    "                \n",
    "                \"\"\"Load and save mask as separate tif file(s), one for each class\"\"\"\n",
    "                # Count number of mask bands (bands - 4)\n",
    "                masks = src.count - 4\n",
    "                \n",
    "                if masks < 2:\n",
    "                    # read mask\n",
    "                    m = src.read(5, window=window)\n",
    "                    \n",
    "                    # Open a new Tiff data file in which to save the image mask (use class 1 for now)                    \n",
    "                    with rasterio.open((mask_dir + chip_name + '_line_mask.tif'), 'w', driver='GTiff',\n",
    "                                       height=m.shape[0], width=m.shape[1], count=1,\n",
    "                                       dtype=rasterio.uint16, crs=src.crs, \n",
    "                                       transform=src.transform) as new_img:\n",
    "                        # Write the mask to the new GeoTiff            \n",
    "                        new_img.write(m, 1)\n",
    "                \n",
    "                else:\n",
    "                                        \n",
    "                    for a in (1, masks):\n",
    "                        \n",
    "                        # read mask\n",
    "                        m = src.read(4 + a, window=window)\n",
    "                        \n",
    "                        # set type of aquaculture class\n",
    "                        if a == 1: \n",
    "                            types = 'raft'\n",
    "                        else: \n",
    "                            types = 'line'\n",
    "                    \n",
    "                        # Open a new Tiff data file in which to save the image mask. Label with class number                    \n",
    "                        with rasterio.open((mask_dir + chip_name + '_' + types + '_mask.tif'), 'w', driver='GTiff',\n",
    "                                           height=m.shape[0], width=m.shape[1], count=1,\n",
    "                                           dtype=rasterio.uint16, crs=src.crs, \n",
    "                                           transform=src.transform) as new_img:\n",
    "                            # Write the mask to the new GeoTiff            \n",
    "                            new_img.write(m, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the function to process the labeled Planet scenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filename: 20180410_020422_0f31_3B_AnalyticMS_SR_labels.tif\n",
      "image name: 20180410_020422_0f31\n",
      "filename: 20180409_014042_1015_3B_AnalyticMS_SR_labels.tif\n",
      "image name: 20180409_014042_1015\n"
     ]
    }
   ],
   "source": [
    "# Run the chipping function for the labeled scenes in the 'planet' directory and save in 'prepped' directory\n",
    "scene_dir = os.path.join(pp.DATASET, 'planet')\n",
    "\n",
    "# Run function on complete labeled Planet scenes                            \n",
    "prep_labeled_scenes(scene_dir, pp.PREPPED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotated Image Chips\n",
    "\n",
    "For the Planet scenes that were annotated after being segmented into image chips, the same process of creating directories for each image chip and mask in `train` is performed. Annotations for all image chips created from a single Planet scene are recorded in a JSON file stored in that scenes folder within `gridded_planet`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def prep_labeled_chips(chip_dir):\n",
    "    \n",
    "    \"\"\"Takes a directory of Planet image chips and a JSON file with object annotations and\n",
    "    creates a 'masks' directory containing object instance masks\"\"\"\n",
    "    \n",
    "    # Find all gridded planet scenes\n",
    "    scenes = np.array(os.listdir(chip_dir))\n",
    "    \n",
    "    # Find all files in scene directories\n",
    "    scene_files = [os.listdir(os.path.join(chip_dir, scene)) for scene in scenes]\n",
    "    \n",
    "    # Flatten list of lists\n",
    "    scene_files = sum(scene_files, [])\n",
    "    \n",
    "    # Pull out label files\n",
    "    scene_labels = [file for file in scene_files if \"_labels_\" in file]\n",
    "    \n",
    "    # Loop over annotated scenes\n",
    "    for label in scene_labels:\n",
    "        \n",
    "        # Pull out scene names of labels\n",
    "        scene = label.split(\"_labels\")[0]\n",
    "    \n",
    "        # Set directory for label\n",
    "        scene_dir = os.path.join(chip_dir, scene)\n",
    "        \n",
    "        # Create \"class_masks\" directory to store chip masks\n",
    "        masks_dir = os.path.join(scene_dir, 'class_masks')\n",
    "        pathlib.Path(masks_dir).mkdir(parents=True, exist_ok=True)\n",
    "               \n",
    "        # We mostly care about the x and y coordinates of each region\n",
    "        annotations = json.load(open(os.path.join(scene_dir, label)))\n",
    "        annotations = list(annotations.values())  # don't need the dict keys\n",
    "\n",
    "        # The VIA tool saves images in the JSON even if they don't have any\n",
    "        # annotations. Skip unannotated images.\n",
    "        annotations = [a for a in annotations if a['regions']]\n",
    "    \n",
    "        for a in annotations:    \n",
    "                        \n",
    "            chip = a['filename'].split('.png')[0]\n",
    "            print(chip)            \n",
    "            \n",
    "            # Read geotiff for chip\n",
    "            gtiff = scene_dir +  '/chips/' + chip + '.tif'\n",
    "            src = rasterio.open(gtiff)\n",
    "            \n",
    "            # Use try to only extract masks for chips with complete annotations and class labels\n",
    "            try:\n",
    "                                        \n",
    "                \"\"\"Code for processing VGG annotations from Matterport balloon color splash sample\"\"\"\n",
    "                # Load annotations\n",
    "                # VGG Image Annotator saves each image in the form:\n",
    "                # { 'filename': '28503151_5b5b7ec140_b.jpg',\n",
    "                #   'regions': {\n",
    "                #       '0': {\n",
    "                #           'region_attributes': {},\n",
    "                #           'shape_attributes': {\n",
    "                #               'all_points_x': [...],\n",
    "                #               'all_points_y': [...],\n",
    "                #               'name': 'polygon'}},\n",
    "                #       ... more regions ...\n",
    "                #   },\n",
    "                #   'size': 100202\n",
    "                # } \n",
    "        \n",
    "                # Get the aquaculture class of each polygon    \n",
    "                polygon_types = [r['region_attributes'] for r in a['regions']]        \n",
    "\n",
    "                # Get unique aquaculture classes in annotations\n",
    "                types = set(val for dic in polygon_types for val in dic.values())            \n",
    "\n",
    "                for t in types:\n",
    "                    # Get the x, y coordinaets of points of the polygons that make up\n",
    "                    # the outline of each object instance. There are stores in the\n",
    "                    # shape_attributes (see json format above) \n",
    "\n",
    "                    # Pull out polygons of that type               \n",
    "                    polygons = [r['shape_attributes'] for r in a['regions'] if r['region_attributes']['class'] == t]            \n",
    "\n",
    "                    # Draw mask using height and width of Geotiff\n",
    "                    mask = np.zeros([src.height, src.width], dtype=np.uint8)\n",
    "\n",
    "                    for p in polygons:\n",
    "\n",
    "                        # Get indexes of pixels inside the polygon and set them to 1\n",
    "                        rr, cc = skimage.draw.polygon(p['all_points_y'], p['all_points_x'])                    \n",
    "                        mask[rr, cc] = 1            \n",
    "\n",
    "                    # Open a new GeoTiff data file in which to save the image chip\n",
    "                    with rasterio.open((masks_dir + '/' + chip + '_' + str(t) + '_mask.tif'), 'w', driver='GTiff',\n",
    "                               height=src.shape[0], width=src.shape[1], count=1,\n",
    "                               dtype=rasterio.ubyte, crs=src.crs, \n",
    "                               transform=src.transform) as new_img:\n",
    "\n",
    "                        # Write the rescaled image to the new GeoTiff\n",
    "                        new_img.write(mask.astype('uint8'),1)\n",
    "\n",
    "            except KeyError:                \n",
    "                print(chip + ' missing aquaculture class assignment')\n",
    "                # write chip name to file for double checking\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run chip labeling function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run function                    \n",
    "prep_labeled_chips(PLANET_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move Gridded Images and Masks to Prepped Directory\n",
    "\n",
    "After creating class-specific masks from the JSON annotations, we need to move each image and it's mask(s) to the `prepped_planet` folder with the other images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile\n",
    "from shutil import copy2\n",
    "\n",
    "# Function to move images and masks to train folder\n",
    "def move_gridded_images(chips_dir, prep_dir):\n",
    "    \n",
    "    \"\"\"Takes a directory of Planet image chips and class masks and moves chips and their masks to \n",
    "    their own directories within the train directory\"\"\"\n",
    "    \n",
    "    # Find all gridded planet scenes\n",
    "    scenes = np.array(next(os.walk(chips_dir))[1])   \n",
    "    # Find scenes that have 'class_masks' directory and thus have had masks prepared\n",
    "    scenes = [s for s in scenes if 'class_masks' in os.listdir(os.path.join(chips_dir, s))]\n",
    "    \n",
    "    # Get unique image chip ids for mask files\n",
    "    masks = [os.listdir(os.path.join(chips_dir, scene, 'class_masks')) for scene in scenes]\n",
    "    masks = sum(masks, []) # flatten nested lists\n",
    "    masks = [mask for mask in masks if mask != '.DS_Store'] # remove stupid DS_Store file\n",
    "    \n",
    "    # Get set of chip ids for masks\n",
    "    chips = [mask.split('_')[0:5] for mask in masks]\n",
    "    chips = set(\"%s_%s_%s_%s_%s\" % (m[0],m[1],m[2],m[3],m[4]) for m in chips)\n",
    "    \n",
    "    # Loop over mask chip ids and copy image and masks to train folder\n",
    "    for chip in chips:\n",
    "                \n",
    "        # Create directory for chip, chip image, and chip class masks in PREPPED_DIR\n",
    "        chip_dir = os.path.join(prep_dir, chip)\n",
    "        chip_image_dir = os.path.join(chip_dir, 'image')\n",
    "        chip_masks_dir = os.path.join(chip_dir, 'class_masks')\n",
    "        \n",
    "        # list of directories to map over\n",
    "        dirs = [chip_dir, chip_image_dir, chip_masks_dir]\n",
    "\n",
    "        # Make chip directory and subdirectories\n",
    "        for d in dirs:\n",
    "            pathlib.Path(d).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Image chip location. Chips are stored in scene directories, so use first 20 chrs\n",
    "        # to indicate scene directory of chip\n",
    "        scene_dir = os.path.join(chips_dir, chip[0:20])\n",
    "        chip_filename = scene_dir + '/chips/' + chip + '.tif'\n",
    "        \n",
    "        # get chip mask files\n",
    "        chip_masks = [mask for mask in masks if chip + '_' in mask]\n",
    "        mask_filenames = [scene_dir + '/class_masks/' + mask for mask in chip_masks]\n",
    "\n",
    "        print(scene_dir)\n",
    "        print(chip_filename)\n",
    "        print(mask_filenames)\n",
    "        \n",
    "        # Copy image chip and masks from scene directory in 'gridded_planet' \n",
    "        # to chip directory in 'prepped_planet'\n",
    "        # Copy chips\n",
    "        copy2(chip_filename, chip_image_dir)\n",
    "        # Copy masks\n",
    "        for m in mask_filenames:\n",
    "            copy2(m, chip_masks_dir)\n",
    "                \n",
    "move_gridded_images(PLANET_DIR, PREPPED_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Empty Images\n",
    "\n",
    "Find prepped images that don't contain any objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgs_without_objects(directory):\n",
    "\n",
    "    # Get directories inside prepped folder\n",
    "    images = os.listdir(directory)\n",
    "    images.remove('.DS_Store')\n",
    "\n",
    "    # List to store files with no instances\n",
    "    no_objects = []\n",
    "\n",
    "    # For each file, check if any class mask file exists\n",
    "    for i in images:\n",
    "\n",
    "        # get list of class masks\n",
    "        masks = os.listdir(os.path.join(directory, i,'class_masks'))\n",
    "\n",
    "        # Empty vector of instances\n",
    "        instances = []\n",
    "\n",
    "        # Loop over masks and calculate instances\n",
    "        for m in masks:\n",
    "\n",
    "            arr = skio.imread(os.path.join(os.path.join(pp.PREPPED, i,'class_masks', m)))\n",
    "            blob_labels = measure.label(arr, background=0)\n",
    "            blob_vals = np.sum(np.unique(blob_labels))\n",
    "            instances.append(blob_vals)\n",
    "\n",
    "        # Find total number of instances\n",
    "        if np.sum(instances) == 0:\n",
    "            no_objects.append(i)\n",
    "\n",
    "    return no_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Get list of images without objects\n",
    "images_to_remove = imgs_without_objects(pp.TRAIN)\n",
    "print(images_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "# Remove images from PREPPED DIR\n",
    "for f in images_to_remove:\n",
    "    if not f.startswith('.'):\n",
    "        shutil.rmtree(os.path.join(pp.PREPPED,f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
