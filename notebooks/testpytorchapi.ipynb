{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model pytorch only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bizarre error, the order of imports matters here. If DefaultPredictor isn't imported after numpy, etc. then kenrel restarts\n",
    "import os\n",
    "import skimage.io as skio\n",
    "from skimage import img_as_ubyte, exposure\n",
    "from PIL import Image as pilimg\n",
    "import warnings\n",
    "import numpy as np\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine.defaults import DefaultPredictor\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "import detectron2.data.transforms as T\n",
    "import torch\n",
    "\n",
    "def load_and_edit_cfg_for_inference(cfg_path= \"../app/pytorch_api/config.yaml\",\n",
    "                                   model_weights_path = \"../app/pytorch_api/best-mrcnn-nebraska-model-rgb-jpeg-split-geo-nebraska-freeze0-withseed.pth\"):\n",
    "    cfg = get_cfg()    # obtain detectron2's default config\n",
    "    cfg.CONFIG_NAME = '' # add new configs for your own custom components\n",
    "    cfg.DATASET_PATH = ''\n",
    "    cfg.merge_from_file(cfg_path)   # load values from a file\n",
    "    cfg.MODEL.WEIGHTS = model_weights_path\n",
    "    cfg.INPUT.MIN_SIZE_TEST = 800\n",
    "    cfg.INPUT.MAX_SIZE_TEST = 1333\n",
    "    model_cfg = cfg.clone()\n",
    "    return model_cfg\n",
    "\n",
    "def load_model_for_inference(cfg):\n",
    "    print('pytorch_classifier.py: Loading model...')\n",
    "    model = build_model(cfg)  # returns a torch.nn.Module\n",
    "    model.eval()\n",
    "\n",
    "    checkpointer = DetectionCheckpointer(model)\n",
    "    checkpointer.load(cfg.MODEL.WEIGHTS); # ; suppresses long output\n",
    "    return model\n",
    "\n",
    "def run_model_single_image(model):\n",
    "    img = skio.imread(\"../images/aoi_restricted_LT05_CU_015009_20050722_20190102_C01_V0_-169665_1934999.jpg\")\n",
    "    rgb_img = img[:,:,::-1] # assumes image is in BGR order, puts it in RGB order since model expects RGB\n",
    "    aug = T.ResizeShortestEdge(\n",
    "            [cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST], cfg.INPUT.MAX_SIZE_TEST\n",
    "        )\n",
    "    with torch.no_grad():\n",
    "        height, width = img.shape[:2]\n",
    "        print(rgb_img.dtype)\n",
    "        img = aug.get_transform(rgb_img).apply_image(rgb_img)\n",
    "        img = torch.as_tensor(img.astype(\"float32\").transpose(2, 0, 1))\n",
    "        inputs = {\"image\": img, \"height\": height, \"width\": width}\n",
    "        predictions = model([inputs])\n",
    "    cpu_output = predictions[0][\"instances\"].to(\"cpu\")\n",
    "    return cpu_output, rgb_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your model function\n",
    "cfg = load_and_edit_cfg_for_inference()\n",
    "model = load_model_for_inference(cfg)\n",
    "predictions, rgb_img = run_model_single_image(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "import matplotlib.pyplot as plt\n",
    "metadata = MetadataCatalog.get(\"test\")\n",
    "vis_p = Visualizer(rgb_img, metadata, instance_mode=ColorMode.SEGMENTATION)\n",
    "\n",
    "# move to cpu\n",
    "# instances = result['instances']\n",
    "vis_pred_im = vis_p.draw_instance_predictions(predictions).get_image()\n",
    "\n",
    "def show_im(image, ax, taskID):\n",
    "    # Show area outside image boundaries.\n",
    "    ax.axis('off')\n",
    "    ax.imshow(image)\n",
    "    plt.savefig(taskID)\n",
    "    return ax\n",
    "\n",
    "plt.rcParams['font.size'] = 20\n",
    "plt.rcParams['axes.linewidth'] = 2\n",
    "plt.style.use(\"seaborn\")\n",
    "fig,ax = plt.subplots(figsize=(10,10))\n",
    "show_im(vis_pred_im,ax, \"taskid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.cpp_extension import CUDA_HOME\n",
    "print(torch.cuda.is_available(), CUDA_HOME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_rescale_tif(img_tile, clamp_low=262, clamp_high=1775): # Landsat 5 ARD .25 and 97.75 percentile range for Nebraska\n",
    "    img_array = skio.imread(img_tile)\n",
    "    img_array = exposure.rescale_intensity(img_array, in_range=(clamp_low, clamp_high))  # Landsat 5 ARD .25 and 97.75 percentile range.\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        img_array = img_as_ubyte(img_array)\n",
    "    return img_array\n",
    "\n",
    "def save_rescaled_jpeg(old_tif_path, jpeg_dir, rescaled_arr):\n",
    "    img_pil = pilimg.fromarray(rescaled_arr)\n",
    "    fid = os.path.basename(old_tif_path).split(\".tif\")[0]\n",
    "    jpeg_path = os.path.join(jpeg_dir, fid + \".jpg\")\n",
    "    # Export chip images\n",
    "    with open(Path(jpeg_path), 'w') as dst:\n",
    "        img_pil.save(dst, format='JPEG', subsampling=0, quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "detectron2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "torchvision.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cropmask-env]",
   "language": "python",
   "name": "conda-env-cropmask-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
