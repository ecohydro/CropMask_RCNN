{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from PIL import Image\n",
    "from cropmask.coco_convert import split_save_train_validation_test_df, save_coco_annotation, create_coco_dataset\n",
    "from cropmask.misc import parse_yaml, make_dirs\n",
    "\n",
    "from cropmask import detectron2_reclass # fair amount of stuff goes on in here to make detectron work for this project.\n",
    "from detectron2.data.datasets import register_coco_instances, load_coco_json\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import cv2\n",
    "import random\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.exposure import rescale_intensity\n",
    "import matplotlib.pyplot as plt\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor, launch\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from cropmask.misc import max_normalize, percentile_rescale\n",
    "from cropmask.detectron2_cropmask_cfg import cfg\n",
    "from cropmask import detectron2_reclass # fair amount of stuff goes on in here to make detectron work for this project.\n",
    "\n",
    "tiles_path = Path(cfg.DATASET_PATH) / \"tiles\"\n",
    "train, validation, test = split_save_train_validation_test_df(tiles_path, save_empty_tiles=False)\n",
    "coco_path = Path(cfg.DATASET_PATH) / \"coco\"\n",
    "\n",
    "def read_and_mean(path):\n",
    "    arr = rasterio.open(path).read()\n",
    "    fill_values = np.mean(arr, axis=tuple(range(1, arr.ndim)))\n",
    "    return fill_values\n",
    "    \n",
    "def read_and_variance(path):\n",
    "    arr = rasterio.open(path).read()\n",
    "    fill_values = np.var(arr, axis=tuple(range(1, arr.ndim)))\n",
    "    return fill_values\n",
    "\n",
    "def calc_stat(df, func, include_empty=False):\n",
    "    \"\"\"\n",
    "    func should operate on a single array of order [band, H, W]\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    new_df = df[df.is_empty == include_empty]\n",
    "    new_df['fill_values'] = new_df['image_tiles'].apply(func)\n",
    "    new_df = pd.DataFrame(new_df.fill_values.tolist(), columns=['0', '1', '2'])\n",
    "    return new_df\n",
    "\n",
    "def max_norm_channels(arr):\n",
    "    \"\"\"\n",
    "    arr must be of shape (w, h, channel)\n",
    "    \"\"\"\n",
    "    arr = arr.copy()\n",
    "    maxes = np.nanmax(arr, axis=(0,1))\n",
    "    return arr / maxes\n",
    "\n",
    "def make_vis_im(img):\n",
    "    img = img[:, :, ::-1]\n",
    "    normalized = max_norm_channels(np.where(img < 0, 0, img))\n",
    "    rescaled = rescale_intensity(normalized, out_range=(0,255))\n",
    "    masked = np.where(rescaled==0, np.nan, rescaled)\n",
    "    return masked\n",
    "\n",
    "mean_df = calc_stat(train, read_and_mean)\n",
    "var_df = calc_stat(train, read_and_variance)\n",
    "\n",
    "channel_means = mean_df.mean(axis=0).values\n",
    "channel_stds = np.sqrt(var_df.mean(axis=0).values)\n",
    "\n",
    "train_coco_instances_path = str(coco_path / \"instances_train.json\")\n",
    "val_coco_instances_path = str(coco_path / \"instances_val.json\")\n",
    "test_coco_instances_path = str(coco_path / \"instances_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (coco_path / \"instances_train.json\").exists() is False:\n",
    "    train_coco_dict = create_coco_dataset(train)\n",
    "    val_coco_dict = create_coco_dataset(validation)\n",
    "    test_coco_dict = create_coco_dataset(test)\n",
    "    save_coco_annotation(train_coco_instances_path, train_coco_dict)\n",
    "    save_coco_annotation(val_coco_instances_path, val_coco_dict)\n",
    "    save_coco_annotation(test_coco_instances_path, test_coco_dict)\n",
    "# register each val and test set if there are more than one.\n",
    "register_coco_instances(cfg.DATASETS.TRAIN[0], {}, train_coco_instances_path, str(next(tiles_path.glob(\"*image*\"))))\n",
    "register_coco_instances(cfg.DATASETS.VALIDATION[0], {}, val_coco_instances_path, str(next(tiles_path.glob(\"*image*\"))))\n",
    "register_coco_instances(cfg.DATASETS.TEST[0], {}, test_coco_instances_path, str(next(tiles_path.glob(\"*image*\"))))\n",
    "\n",
    "train_json = load_coco_json(train_coco_instances_path,  str(next(tiles_path.glob(\"*image*\"))))\n",
    "val_json = load_coco_json(val_coco_instances_path,  str(next(tiles_path.glob(\"*image*\"))))\n",
    "test_json = load_coco_json(test_coco_instances_path,  str(next(tiles_path.glob(\"*image*\"))))\n",
    "try:\n",
    "    os.makedirs(cfg.OUTPUT_DIR, exist_ok=False)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_means)\n",
    "print(channel_stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Truth Labels and Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in random.sample(train_json, 1):\n",
    "    if len(d['annotations']) > 0:\n",
    "        img = imread(d[\"file_name\"])\n",
    "        img = img[:, :, ::-1]\n",
    "        normalized = max_norm_channels(np.where(img < 0, 0, img))\n",
    "        rescaled = rescale_intensity(normalized, out_range=(0,255))\n",
    "        masked = np.where(rescaled==0, np.nan, rescaled)\n",
    "        visualizer = Visualizer(masked, metadata={}, scale=0.5)\n",
    "        vis = visualizer.draw_dataset_dict(d)\n",
    "        plt.figure(figsize = (8,16))\n",
    "        imshow(vis.get_image())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_0002399.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.1  # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "for d in random.sample(train_json, 1):    \n",
    "    im = imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    vis_im = make_vis_im(im)\n",
    "    visualizer_preds = Visualizer(vis_im,\n",
    "                   scale=1, \n",
    "                   metadata= {}   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    visualizer_labels = Visualizer(vis_im,\n",
    "                   scale=1, \n",
    "                   metadata= {}   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    v = visualizer_preds.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    labels = visualizer_labels.draw_dataset_dict(d)\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2, figsize = (16,16))\n",
    "    imshow(v.get_image(), ax=ax[0])\n",
    "    imshow(labels.get_image(), ax=ax[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"test\", cfg, False, output_dir=\"/datadrive/evaluator_output/\")\n",
    "test_loader = build_detection_test_loader(cfg, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_on_dataset(predictor.model, test_loader, evaluator)\n",
    "# another equivalent way is to use trainer.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
