{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import skimage.io as skio\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import fnmatch\n",
    "from PIL import Image\n",
    "from pycococreatortools import pycococreatortools\n",
    "import cropmask.misc as misc\n",
    "from shutil import copyfile\n",
    "from cropmask.coco_convert import split_save_train_test_df, path_df_to_coco_json\n",
    "from cropmask.misc import parse_yaml, make_dirs\n",
    "import pandas as pd\n",
    "import solaris as sol\n",
    "\n",
    "param_path = \"/home/ryan/work/CropMask_RCNN/test_inspection_config.yaml\"\n",
    "params = parse_yaml(param_path)\n",
    "tiles_path = Path(os.path.join(params['dirs']['root'], params['dirs']['dataset'], \"tiles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_save_train_test_df(tiles_path, save_empty_tiles=False)\n",
    "coco_path = Path(params['dirs']['root']) / params['dirs']['dataset'] / \"coco\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coco_dataset(df):\n",
    "    \"\"\"\n",
    "    Takes a df with paths to images and geojson tiles and creates coco formatted json for training or testing.\n",
    "    \"\"\"\n",
    "    img_lst = df['image_tiles'].to_list()\n",
    "    geojson_lst = df['geojson_tiles'].to_list()\n",
    "    # crazy regex is based on appending scene ID to each tile, including path/row and date info\n",
    "    coco_dict = sol.data.coco.geojson2coco(image_src = [str(i) for i in img_lst],\n",
    "                                       label_src = [str(i) for i in geojson_lst],\n",
    "                                       matching_re=r'(\\d{6}_\\d{8}_\\d{8}_C\\d{2}_V\\d_-?\\d+_\\d+)',\n",
    "                                       license_dict={'CC-BY 4.0': 'https://creativecommons.org/licenses/by/4.0/'},\n",
    "                                       remove_all_multipolygons = True,\n",
    "                                       verbose=0)\n",
    "    return coco_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cropmask.coco_convert import save_coco_annotation\n",
    "from detectron2.data.datasets import register_coco_instances, load_coco_json\n",
    "train_coco_instances_path = str(coco_path / \"instances_train.json\")\n",
    "test_coco_instances_path = str(coco_path / \"instances_test.json\")\n",
    "if (coco_path / \"instances_train.json\").exists() is False:\n",
    "    train_coco_dict = create_coco_dataset(train)\n",
    "    test_coco_dict = create_coco_dataset(test)\n",
    "    save_coco_annotation(train_coco_instances_path, train_coco_dict)\n",
    "    save_coco_annotation(test_coco_instances_path, test_coco_dict)\n",
    "register_coco_instances(\"train_nirrg\", {}, train_coco_instances_path, str(next(tiles_path.glob(\"*image*\"))))\n",
    "register_coco_instances(\"test_nirrg\", {}, test_coco_instances_path, str(next(tiles_path.glob(\"*image*\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_json = load_coco_json(train_coco_instances_path,  str(next(tiles_path.glob(\"*image*\"))))\n",
    "test_json = load_coco_json(test_coco_instances_path,  str(next(tiles_path.glob(\"*image*\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_norm_channels(arr):\n",
    "    \"\"\"\n",
    "    arr must be of shape (w, h, channel)\n",
    "    \"\"\"\n",
    "    arr = arr.copy()\n",
    "    maxes = np.nanmax(arr, axis=(0,1))\n",
    "    return arr / maxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.exposure import rescale_intensity\n",
    "import matplotlib.pyplot as plt\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from cropmask.misc import max_normalize, percentile_rescale\n",
    "\n",
    "for d in random.sample(train_json, 1):\n",
    "    if len(d['annotations']) > 0:\n",
    "        img = imread(d[\"file_name\"])\n",
    "        img = img[:, :, ::-1]\n",
    "        normalized = max_norm_channels(np.where(img < 0, 0, img))\n",
    "        rescaled = rescale_intensity(normalized, out_range=(0,255))\n",
    "        masked = np.where(rescaled==0, np.nan, rescaled)\n",
    "        visualizer = Visualizer(masked, metadata={}, scale=0.5)\n",
    "        vis = visualizer.draw_dataset_dict(d)\n",
    "        plt.figure(figsize = (8,16))\n",
    "        imshow(vis.get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.data import build_detection_train_loader\n",
    "from detectron2.data import build_detection_test_loader\n",
    "from detectron2.data import transforms as T\n",
    "from detectron2.data import detection_utils as utils\n",
    "import copy\n",
    "import torch\n",
    "\n",
    "def tif_dataset_mapper(dataset_dict):\n",
    "    # Implement a mapper, similar to the default DatasetMapper, but with your own customizations\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)  # it will be modified by code below\n",
    "    image = utils.read_image(dataset_dict[\"file_name\"])\n",
    "#     image, transforms = T.apply_transform_gens([T.Resize((800, 800))], image)\n",
    "    dataset_dict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\"))\n",
    "\n",
    "#     annos = [\n",
    "#         utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "#         for obj in dataset_dict.pop(\"annotations\")\n",
    "#         if obj.get(\"iscrowd\", 0) == 0\n",
    "#     ]\n",
    "\n",
    "    annos = [\n",
    "        obj\n",
    "        for obj in dataset_dict.pop(\"annotations\")\n",
    "        if obj.get(\"iscrowd\", 0) == 0\n",
    "    ]\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict[\"instances\"] = utils.filter_empty_instances(instances)\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.evaluation import COCOEvaluator, DatasetEvaluators\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name):\n",
    "        output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
    "        evaluators = [COCOEvaluator(dataset_name, cfg, True, output_folder)]\n",
    "        return DatasetEvaluators(evaluators)\n",
    "\n",
    "    @classmethod\n",
    "    def build_test_loader(cls, cfg, dataset_name):\n",
    "        return build_detection_test_loader(cfg, dataset_name, mapper=tif_dataset_mapper)\n",
    "\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg):\n",
    "        return build_detection_train_loader(cfg, mapper=tif_dataset_mapper)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.config import get_cfg\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (\"train_nirrg\",)\n",
    "cfg.DATASETS.TEST = (\"test_nirrg\",)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 3000 \n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512   # this is the default\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # only has one class \n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = Trainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at training curves in tensorboard:\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "dataset_dicts = get_balloon_dicts(\"balloon/val\")\n",
    "for d in random.sample(dataset_dicts, 3):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=balloon_metadata, \n",
    "                   scale=0.8, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"balloon_val\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"balloon_val\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "# another equivalent way is to use trainer.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling/Debugging raster tiler and filling nan values with means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_path = list(Path(\"/datadrive/test-ard-june-sept-nirrg/scene\").glob(\"LT05_CU_*\"))[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray \n",
    "import rioxarray\n",
    "xarr = xarray.open_rasterio(scene_path)\n",
    "\n",
    "xarr = xarr.transpose(\"y\", \"x\", \"band\")\n",
    "\n",
    "xarr = xarr.where(xarr != -9999.0)/32767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flip(xarr, axis=-1).plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import us\n",
    "from cropmask import io_utils\n",
    "import xarray\n",
    "import rioxarray\n",
    "nebraska_url = us.states.NE.shapefile_urls('state')\n",
    "gdf = io_utils.zipped_shp_url_to_gdf (nebraska_url)\n",
    "crs=xarray.open_rasterio(scene_path).rio.crs\n",
    "bounds_poly = gdf.to_crs(crs)['geometry'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solaris.utils.core import _check_crs, _check_rasterio_im_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = _check_rasterio_im_load(str(scene_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "mask_geometry = bounds_poly.intersection(box(*src.bounds)) # prevents enlarging raster to size of aoi_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.mask import mask as rasterio_mask\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr, transform = rasterio_mask(src, [mask_geometry], all_touched=False, invert=False, nodata=src.meta['nodata'], filled=True, crop=False, pad=False, pad_width=0.5, indexes=[1,2,3])\n",
    "\n",
    "with rasterio.open(\"/datadrive/tmp-masked.tif\", 'w', **src.profile) as dest:\n",
    "    dest.write(arr)\n",
    "    dest.close()\n",
    "src = _check_rasterio_im_load(\"/datadrive/tmp-masked.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr, transform = rasterio_mask(src, [mask_geometry], all_touched=False, invert=False, nodata=src.meta['nodata'], filled=False, crop=False, pad=False, pad_width=0.5, indexes=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_by_mean(arr):\n",
    "    \"\"\"\n",
    "    Fills a masked array of shape (channel, H, W) by the channel means of the whole array for each channel.\n",
    "    This is used to fill the channel means of the image that is tiled if fill_by_mean=True.\n",
    "    \"\"\"\n",
    "    means = arr.mean(axis=(1,2))\n",
    "    arr.soften_mask()\n",
    "    for i,mean in enumerate(means):\n",
    "        arr[i][arr.mask[i]==True] = mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.soften_mask()\n",
    "arr[0][0] = np.ma.masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_path = '/datadrive/test-ard-june-sept-nirrg/tiles/image_tiles/LT05_CU_013009_20050711_20190102_C01_V0_-511746_1962203.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xarr = xarray.open_rasterio(scene_path)\n",
    "\n",
    "xarr = xarr.transpose(\"y\", \"x\", \"band\")\n",
    "\n",
    "xarr = xarr.where(xarr != -9999.0)/32767\n",
    "\n",
    "\n",
    "gpd.GeoDataFrame(geometry=[bounds_poly]).plot(ax=ax, color=None,edgecolor='k', facecolor=\"none\")\n",
    "np.flip(xarr, axis=-1).plot.imshow(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import cascaded_union\n",
    "from shapely.geometry import box\n",
    "total_shape = cascaded_union([box(*i) for i in raster_tiler.tile_bounds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_bounds_crs = raster_tiler.tile(str(scene_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(bounds_poly, str):\n",
    "    gj = json.loads(open(geometry).read())\n",
    "\n",
    "    features = gj['features']\n",
    "    if not len(features) == 1:\n",
    "        print('Feature collection must only contain one feature')\n",
    "        sys.exit(1)\n",
    "\n",
    "    geometry = shape(features[0]['geometry'])\n",
    "\n",
    "elif isinstance(geometry, list) or isinstance(geometry, np.ndarray):\n",
    "    assert len(geometry) == 4\n",
    "    geometry = box(*geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_g = geojson_lst[0:5]\n",
    "\n",
    "# sample_g = sample_g[::-1]\n",
    "\n",
    "# sample_i = img_lst[0:5]\n",
    "\n",
    "# gdf = gpd.read_file(geojson_lst[183])\n",
    "\n",
    "# from solaris.vector.polygon import remove_multipolygons\n",
    "\n",
    "# gdf['geometry'][0]\n",
    "\n",
    "# remove_multipolygons(gdf).reset_index(drop=True)\n",
    "\n",
    "# remove_multipolygons(gdf)['geometry'][0]\n",
    "\n",
    "# import geopandas as gpd\n",
    "# gpd.read_file(geojson_lst[183])['geometry'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
