{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "from PIL import Image\n",
    "from cropmask.coco_convert import split_save_train_validation_test_df, save_coco_annotation, create_coco_dataset\n",
    "from cropmask.misc import parse_yaml, make_dirs\n",
    "\n",
    "from cropmask import detectron2_reclass # fair amount of stuff goes on in here to make detectron work for this project.\n",
    "from detectron2.data.datasets import register_coco_instances, load_coco_json\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import cv2\n",
    "import random\n",
    "from skimage.io import imshow, imread\n",
    "from skimage.exposure import rescale_intensity\n",
    "import matplotlib.pyplot as plt\n",
    "# import some common detectron2 utilities\n",
    "from detectron2.engine import DefaultPredictor, launch\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from cropmask.misc import max_normalize, percentile_rescale\n",
    "from cropmask.detectron2_cropmask_cfg import cfg\n",
    "from cropmask import detectron2_reclass # fair amount of stuff goes on in here to make detectron work for this project.\n",
    "\n",
    "\n",
    "param_path = \"/home/ryan/work/CropMask_RCNN/test_inspection_config.yaml\"\n",
    "params = parse_yaml(param_path)\n",
    "tiles_path = Path(os.path.join(params['dirs']['root'], params['dirs']['dataset'], \"tiles\"))\n",
    "\n",
    "train, validation, test = split_save_train_validation_test_df(tiles_path, save_empty_tiles=False)\n",
    "coco_path = Path(params['dirs']['root']) / params['dirs']['dataset'] / \"coco\"\n",
    "\n",
    "train_coco_instances_path = str(coco_path / \"instances_train.json\")\n",
    "val_coco_instances_path = str(coco_path / \"instances_val.json\")\n",
    "test_coco_instances_path = str(coco_path / \"instances_test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (coco_path / \"instances_train.json\").exists() is False:\n",
    "    train_coco_dict = create_coco_dataset(train)\n",
    "    val_coco_dict = create_coco_dataset(validation)\n",
    "    test_coco_dict = create_coco_dataset(test)\n",
    "    save_coco_annotation(train_coco_instances_path, train_coco_dict)\n",
    "    save_coco_annotation(val_coco_instances_path, val_coco_dict)\n",
    "    save_coco_annotation(test_coco_instances_path, test_coco_dict)\n",
    "# register each val and test set if there are more than one.\n",
    "register_coco_instances(cfg.DATASETS.TRAIN[0], {}, train_coco_instances_path, str(next(tiles_path.glob(\"*image*\"))))\n",
    "register_coco_instances(cfg.DATASETS.VALIDATION[0], {}, val_coco_instances_path, str(next(tiles_path.glob(\"*image*\"))))\n",
    "register_coco_instances(cfg.DATASETS.TEST[0], {}, test_coco_instances_path, str(next(tiles_path.glob(\"*image*\"))))\n",
    "\n",
    "train_json = load_coco_json(train_coco_instances_path,  str(next(tiles_path.glob(\"*image*\"))))\n",
    "val_json = load_coco_json(val_coco_instances_path,  str(next(tiles_path.glob(\"*image*\"))))\n",
    "test_json = load_coco_json(test_coco_instances_path,  str(next(tiles_path.glob(\"*image*\"))))\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = detectron2_reclass.Trainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_norm_channels(arr):\n",
    "    \"\"\"\n",
    "    arr must be of shape (w, h, channel)\n",
    "    \"\"\"\n",
    "    arr = arr.copy()\n",
    "    maxes = np.nanmax(arr, axis=(0,1))\n",
    "    return arr / maxes\n",
    "\n",
    "for d in random.sample(train_json, 5):\n",
    "    if len(d['annotations']) > 0:\n",
    "        img = imread(d[\"file_name\"])\n",
    "        img = img[:, :, ::-1]\n",
    "        normalized = max_norm_channels(np.where(img < 0, 0, img))\n",
    "        rescaled = rescale_intensity(normalized, out_range=(0,255))\n",
    "        masked = np.where(rescaled==0, np.nan, rescaled)\n",
    "        visualizer = Visualizer(masked, metadata={}, scale=0.5)\n",
    "        vis = visualizer.draw_dataset_dict(d)\n",
    "        plt.figure(figsize = (8,16))\n",
    "        imshow(vis.get_image())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7   # set the testing threshold for this model\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "dataset_dicts = get_balloon_dicts(\"balloon/val\")\n",
    "for d in random.sample(dataset_dicts, 3):    \n",
    "    im = cv2.imread(d[\"file_name\"])\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1],\n",
    "                   metadata=balloon_metadata, \n",
    "                   scale=0.8, \n",
    "                   instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels\n",
    "    )\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    cv2_imshow(v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"balloon_val\", cfg, False, output_dir=\"./output/\")\n",
    "val_loader = build_detection_test_loader(cfg, \"balloon_val\")\n",
    "inference_on_dataset(trainer.model, val_loader, evaluator)\n",
    "# another equivalent way is to use trainer.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profiling/Debugging solaris raster tiler and filling nan values with means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_path = list(Path(\"/datadrive/test-ard-june-sept-nirrg/scene\").glob(\"LT05_CU_*\"))[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray \n",
    "import rioxarray\n",
    "xarr = xarray.open_rasterio(scene_path)\n",
    "\n",
    "xarr = xarr.transpose(\"y\", \"x\", \"band\")\n",
    "\n",
    "xarr = xarr.where(xarr != -9999.0)/32767"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.flip(xarr, axis=-1).plot.imshow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import us\n",
    "from cropmask import io_utils\n",
    "import xarray\n",
    "import rioxarray\n",
    "nebraska_url = us.states.NE.shapefile_urls('state')\n",
    "gdf = io_utils.zipped_shp_url_to_gdf (nebraska_url)\n",
    "crs=xarray.open_rasterio(scene_path).rio.crs\n",
    "bounds_poly = gdf.to_crs(crs)['geometry'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from solaris.utils.core import _check_crs, _check_rasterio_im_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = _check_rasterio_im_load(str(scene_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import box\n",
    "mask_geometry = bounds_poly.intersection(box(*src.bounds)) # prevents enlarging raster to size of aoi_boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.mask import mask as rasterio_mask\n",
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr, transform = rasterio_mask(src, [mask_geometry], all_touched=False, invert=False, nodata=src.meta['nodata'], filled=True, crop=False, pad=False, pad_width=0.5, indexes=[1,2,3])\n",
    "\n",
    "with rasterio.open(\"/datadrive/tmp-masked.tif\", 'w', **src.profile) as dest:\n",
    "    dest.write(arr)\n",
    "    dest.close()\n",
    "src = _check_rasterio_im_load(\"/datadrive/tmp-masked.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr, transform = rasterio_mask(src, [mask_geometry], all_touched=False, invert=False, nodata=src.meta['nodata'], filled=False, crop=False, pad=False, pad_width=0.5, indexes=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_by_mean(arr):\n",
    "    \"\"\"\n",
    "    Fills a masked array of shape (channel, H, W) by the channel means of the whole array for each channel.\n",
    "    This is used to fill the channel means of the image that is tiled if fill_by_mean=True.\n",
    "    \"\"\"\n",
    "    means = arr.mean(axis=(1,2))\n",
    "    arr.soften_mask()\n",
    "    for i,mean in enumerate(means):\n",
    "        arr[i][arr.mask[i]==True] = mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.soften_mask()\n",
    "arr[0][0] = np.ma.masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src.profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_path = '/datadrive/test-ard-june-sept-nirrg/tiles/image_tiles/LT05_CU_013009_20050711_20190102_C01_V0_-511746_1962203.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "xarr = xarray.open_rasterio(scene_path)\n",
    "\n",
    "xarr = xarr.transpose(\"y\", \"x\", \"band\")\n",
    "\n",
    "xarr = xarr.where(xarr != -9999.0)/32767\n",
    "\n",
    "\n",
    "gpd.GeoDataFrame(geometry=[bounds_poly]).plot(ax=ax, color=None,edgecolor='k', facecolor=\"none\")\n",
    "np.flip(xarr, axis=-1).plot.imshow(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import cascaded_union\n",
    "from shapely.geometry import box\n",
    "total_shape = cascaded_union([box(*i) for i in raster_tiler.tile_bounds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_bounds_crs = raster_tiler.tile(str(scene_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if isinstance(bounds_poly, str):\n",
    "    gj = json.loads(open(geometry).read())\n",
    "\n",
    "    features = gj['features']\n",
    "    if not len(features) == 1:\n",
    "        print('Feature collection must only contain one feature')\n",
    "        sys.exit(1)\n",
    "\n",
    "    geometry = shape(features[0]['geometry'])\n",
    "\n",
    "elif isinstance(geometry, list) or isinstance(geometry, np.ndarray):\n",
    "    assert len(geometry) == 4\n",
    "    geometry = box(*geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_g = geojson_lst[0:5]\n",
    "\n",
    "# sample_g = sample_g[::-1]\n",
    "\n",
    "# sample_i = img_lst[0:5]\n",
    "\n",
    "# gdf = gpd.read_file(geojson_lst[183])\n",
    "\n",
    "# from solaris.vector.polygon import remove_multipolygons\n",
    "\n",
    "# gdf['geometry'][0]\n",
    "\n",
    "# remove_multipolygons(gdf).reset_index(drop=True)\n",
    "\n",
    "# remove_multipolygons(gdf)['geometry'][0]\n",
    "\n",
    "# import geopandas as gpd\n",
    "# gpd.read_file(geojson_lst[183])['geometry'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
